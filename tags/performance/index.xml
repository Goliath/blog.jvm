<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Performance on Bitecode blog</title><link>https://bitecode.blog/tags/performance/</link><description>Recent content in Performance on Bitecode blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 02 Jun 2016 00:00:00 +0000</lastBuildDate><atom:link href="https://bitecode.blog/tags/performance/index.xml" rel="self" type="application/rss+xml"/><item><title>Dumping large MySQL database</title><link>https://bitecode.blog/2016/05/14/mysql-dump-large-database/</link><pubDate>Thu, 02 Jun 2016 00:00:00 +0000</pubDate><guid>https://bitecode.blog/2016/05/14/mysql-dump-large-database/</guid><description>Problem Not going into details of credentials basic mysqldump command looks like this:
mysqldump database &amp;gt; database_dump.sql Dump file size was ~3GB which might take quite long. Especially when the connection to mysql server was not fast enough.
Solution After a few attempts and noticing that it might take too long to fetch all data I found out that there is a nice switch in mysql and mysqldump commands.
--compress, -C Switch will tell mysql server to compress the dump on the fly so you can save a lot of bandwidth.</description></item></channel></rss>